{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar Python 2\n",
    "\n",
    "## 1 File operations in Python\n",
    "The built-in `open()` function returns a file object. The file contents can be read with methods like `read()`, `readline()` or `readlines()`.  \n",
    "The `open()` function has two arguments: the (path and) filename and the open mode:  \n",
    "`\"r\"` – Read only – default. Open file for reading; causes an error if the file is not found.  \n",
    "`\"r+\"` – read and write (update);  \n",
    "`\"a\"` - Append - open file for appending (data is written at the end of the file); creates the file if not found.  \n",
    "`\"w\"` - Write only - open file for writing; creates the file if not found. If the file exists, it is erased.  \n",
    "`\"x\"` - Create - creates a new file; causes an error if the file already exists.  \n",
    "The `readline()` method reads a single line (terminated by the `\\n` character). It returns an empty string if the end of file was reached.  \n",
    "`readlines()` reads all the lines from the file into a list of strings.\n",
    "The maximum number of read characters may be specified as argument: `read(100)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"\" #set path to data files as required\n",
    "\n",
    "#Example 1.a\n",
    "\n",
    "f = open(path+\"Data1.txt\", \"r\")\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1.b: read 100 characters\n",
    "f = open(path+\"Data1.txt\", \"r\")\n",
    "print(f.read(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1.c\n",
    "print(f.readline()) #readline() stops at end of line\n",
    "print(f.readline())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1.d\n",
    "f = open(path+\"Data1.txt\", \"r\")\n",
    "\n",
    "for line in f: #iterating the file object \n",
    "  print(line, end='')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text or binary mode can also be specified in the mode argument:  \n",
    "`\"t\"` - Text - default. Text mode.\n",
    "`\"b\"` - Binary – binary mode (e.g. an image file)\n",
    "\n",
    "`f = open(\"Data1.txt\")`  is equivalent with `f = open(\"Data1.txt\", \"rt\")`  \n",
    "The files should be closed with `f.close()`.  \n",
    "A recommended technique is to use a `with` statement, which takes care of the file closing automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2: using \"with\"\n",
    "with open(path+'Data1.txt') as f:\n",
    "    lines=f.readlines() #read all text lines into a list\n",
    "print(len(lines), 'lines read from file.')\n",
    "\n",
    "for i in range(20):    #print the first 20 lines\n",
    "    print('Line',i+1,':',lines[i],end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `write()` methods takes a string as argument and writes it to a text file. The line delimiters are added automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3: Append data from Data2.txt to Data1.txt\n",
    "\n",
    "f1 = open(path+'Data1.txt', 'a')\n",
    "f2 = open(path+'Data2.txt', 'r')\n",
    "for line in f2:\n",
    "    f1.write(line)\n",
    "f1.close(); f2.close()\n",
    "print(len(open(path+'Data1.txt').readlines()), 'lines in Data1.txt.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 The pandas Package\n",
    "Pandas provides objects and functions for processing tabular data (like spreadsheets and relational databases); it contains advanced indexing mechanisms and complex processing functions. (for a more detailed overview see [this link](https://pandas.pydata.org/docs/getting_started/overview.html)).  \n",
    "### 2.1 Basic data structures\n",
    "Data in pandas is structured by using the one-dimensional **Series** object and the two-dimensional (tabular) **DataFrame** object. Each column in DataFrame is a Series object.\n",
    "\n",
    "The rows are considered as the **axis** 0 of the DataFrame, and columns as **axis 1**. Some methods include an `axis` argument to differentiate between rows and columns processing (e.g. `drop()`, see 2.6 Other dataframe operations).\n",
    "\n",
    "DataFrame objects include an **index** – by default this is an integer value (0, 1, ...) allocated for each row. The index values can be used to access specific rows. The `index` attribute can be used to access the index.\n",
    "The columns have column names (labels) which contain the field / variable names of the data.  \n",
    "Reading csv data into a pandas DataFrame is done with the `read_csv()` method. Similar methods exist for other formats / databases: `read_excel()`, `read_json()`, `read_sql()`.\n",
    "\n",
    "For saving a dataframe to a file, use the methods `to_csv()`, `to_excel()`, `to_json()`, `to_sql()`.\n",
    "The methods `head()` and `tail()` return the first and last n (default: 5) rows, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 4: Csv import, showing basic information about the dataframe\n",
    "\n",
    "import pandas\n",
    "df = pandas.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.index)\n",
    "print('-'*40)\n",
    "print(df.columns)\n",
    "print('-'*40)\n",
    "print(df.head())\n",
    "print('-'*40)\n",
    "#print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Data selection, indexing\n",
    "To access specific data (by row and column) in a DataFrame, two attributes are available:  \n",
    "- **`iloc`**: integer index location - access data using integer indexes of rows and columns (similar to accessing matrix elements);\n",
    "- **`loc`**: access data using column names (labels) and row labels (or index).\n",
    "\n",
    "*a. Using `iloc`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 5: Using iloc for displaying specific rows\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 120)\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.iloc[2], '\\n', type(df.iloc[2]))       #print the 3rd row ==> Series object\n",
    "print('-'*40)\n",
    "print(df.iloc[[1,3,5]], '\\n', type(df.iloc[[1,3,5]])) #print specific rows (as list of row numbers),\n",
    "                        # ==> DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To also select specific columns, a second list element is passed to `iloc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 6\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.iloc[2, 0]) #print the value in 3rd row, first column\n",
    "print('-'*40)\n",
    "print(df.iloc[[1,3,5], [0,2]]) #print specific rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Slices** can be used to specify multiple rows / columns. When using `iloc`, the usual Python slicing is used (including the lower bound, but not the upper bound - see Seminar 1 – Lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 7: Using iloc for displaying specific row(s) – slice notation\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 120)\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.iloc[3:6]) # row slicing\n",
    "#print(df.iloc[:5])\n",
    "#print(df.iloc[15:])\n",
    "\n",
    "print('-'*40)\n",
    "print(df.iloc[7:10, 2:5])  #  rows 7 to 9, columns 2 to 4\n",
    "#print(df.iloc[0, :]) #first row, all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*b. Using loc* -Access data using column names (labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 8: Using loc for displaying rows(records) \n",
    "#           and specific column(s) by label\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.loc[ : ,'NAME_CLIENT'])\n",
    "\n",
    "# when selecting a single column, the following expressions may also be used:\n",
    "#print(df['NAME_CLIENT']) # dictionary-style indexing\n",
    "#print(df.NAME_CLIENT)    # attribute-style access (if column names are strings)\n",
    "print('-'*40)\n",
    "print(df.loc[5, 'NAME_CLIENT']) # row 5, column NAME_CLIENT\n",
    "print('-'*40)\n",
    "print(df.loc[[5,10],['NAME_CLIENT','JOB']]) # rows list, columns list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slice notation can be used with column names, but it **includes the upper bound of the slice (!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 9: Using loc with slicing\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.loc[ :10, 'ID_CLIENT':'JOB']) # ! upper bound is included !\n",
    "\n",
    "#print(df.loc[0, :'JOB']) # slice with upper bound only\n",
    "#print(df.loc[1, 'JOB':]) # slice with lower bound only\n",
    "#print(df.loc[[0,3], : ]) #empty slice (all columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Conditional data selection\n",
    "It's possible to select (filter) data by setting conditions on `loc` / `iloc ` expressions (conditional selection / boolean indexing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 10.a\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.loc[(df['AGE']==35),['NAME_CLIENT']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression `df['AGE']==35` generates a pandas Series (boolean vector) with True / False values for each row, acording to the condition. This series is used as argument for `df.loc` to select the rows which have a corresponding True value. (for more information on boolean indexing see [this link](https://pandas.pydata.org/docs/user_guide/indexing.html#boolean-indexing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 10.b\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "#print(df.loc[ (df['AGE']==35), ['NAME_CLIENT']])\n",
    "print(df['AGE']==35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex conditions can be built using the logical operators: `|` for or, `&` for and, and `~` for not. These must be grouped by using parentheses ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 11: Showing customers with age = 35 who are male\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.loc[(df['AGE']==35)&(df['SEX']=='m'),['NAME_CLIENT','JOB','SEX','AGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 12: Showing customers that are not engineers\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.loc[df['JOB'] != 'Engineer', 'NAME_CLIENT':'INCOME_PER_YEAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using string methods in conditions  \n",
    "String processing methods are accessed through the `.str` attribute of a Series. They generally have the same names as the Python built-in string methods: `str.len(), str.lower(), str.upper(), str.strip(), str.startswith(), str.endswith()` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 13: Showing customers with names ending in 'a'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.loc[df['NAME_CLIENT'].str.endswith(\"a\"),['NAME_CLIENT','SEX']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 14: Showing customers with names starting with 'Ha'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.loc[df['NAME_CLIENT'].str.startswith(\"Ha\"),['NAME_CLIENT','SEX']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame.isin()` method allows to check for the existence of values in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 15: Showing customers which are engineers or professors\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.loc[df['JOB'].isin(['Engineer', 'Professor']),['NAME_CLIENT','SEX', 'JOB']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Setting (modifying) data values\n",
    "The `.loc` / `.iloc` notation allows assignments in order to set (modify) the data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 16: Changing the income for the first record (row)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "print(df.loc[0, 'INCOME_PER_YEAR'])\n",
    "df.loc[0,'INCOME_PER_YEAR']=30000\n",
    "print(df.loc[0, 'INCOME_PER_YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 17: Conditional change: increase income if lower than 5000 \n",
    "#            and age greater than 30. \n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "df1=df.copy() #new dataframe created\n",
    "\n",
    "# initial situation:\n",
    "print(df1.loc[(df1['INCOME_PER_YEAR']<5000)&(df1['AGE']>30), \n",
    "              ['NAME_CLIENT','INCOME_PER_YEAR', 'AGE']])\n",
    "print('-'*40)\n",
    "# increase income:\n",
    "df1.loc[(df1['INCOME_PER_YEAR']<5000)&(df1['AGE']>30),'INCOME_PER_YEAR']=10000\n",
    "# final situation:\n",
    "print(df1.loc[(df1['INCOME_PER_YEAR']==10000)&(df1['AGE']>30), \n",
    "              ['NAME_CLIENT','INCOME_PER_YEAR', 'AGE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Calculating basic statistics\n",
    "The `describe()` method returns a statistical summary of all the numeric columns, or for specified columns.  \n",
    "To show statistics for all columns, use the `include=\"all\"` argument. Notice that different statistics are calculated for the object type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 18: the describe() method\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv',\n",
    "    usecols=['NAME_CLIENT','JOB','SEX','CURRENCY','INCOME_PER_YEAR','DATE','AGE'])\n",
    "\n",
    "print(df.describe())\n",
    "#print(df.describe(include=\"all\"))\n",
    "\n",
    "print('\\n***** describe() on column JOB *****')\n",
    "print(df['JOB'].describe())\n",
    "\n",
    "print('\\n***** describe() on column AGE *****')\n",
    "print(df['AGE'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics: methods `sum(), mean(), median(), nunique(), max(), min()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 19: Descriptive statistics for INCOME_PER_YEAR\n",
    "#import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv',\n",
    "    usecols=['NAME_CLIENT','JOB','SEX','CURRENCY','INCOME_PER_YEAR','DATE','AGE'])\n",
    "\n",
    "print('Total income', df['INCOME_PER_YEAR'].sum())\n",
    "print('Average income', df['INCOME_PER_YEAR'].mean())\n",
    "print('Median of income', df['INCOME_PER_YEAR'].median())\n",
    "print('No. of unique values', df['INCOME_PER_YEAR'].nunique())\n",
    "print('Highest income', df['INCOME_PER_YEAR'].max())\n",
    "print('Lowest income', df['INCOME_PER_YEAR'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column data types are automatically recognized by `read_csv()`.  \n",
    "They are stored in the `.dtypes` attribute.  \n",
    "In some cases it's necessary to set the data type of a column manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 20: showing and changing column data types\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "print(df.dtypes) #what are the types of AGE, DATE ?\n",
    "print('-'*40)\n",
    "\n",
    "df = pd.read_csv(path+'clients_leasing20.csv', parse_dates = ['DATE']) #parse 'DATE' as a date column\n",
    "df.AGE = df.AGE.astype(float) #convert AGE data to float\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing missing values in the data is done with `fillna()`.  \n",
    "It's also possible to use `dropna()` to remove the rows containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 21: Replacing missing values\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20missing.csv',\n",
    "    usecols=['NAME_CLIENT','JOB','SEX','CURRENCY','INCOME_PER_YEAR','DATE','AGE'])\n",
    "\n",
    "print(df['AGE']) #check the output for missing values !\n",
    "#print(df.loc[df['AGE'].isnull()]) #print rows with missing values for  AGE\n",
    "print('-'*40)\n",
    "print(df['AGE'].fillna('missing')) #fill with a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 22: Replace missing values with the mean value\n",
    "#import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20missing.csv',\n",
    "     usecols=['NAME_CLIENT','JOB','SEX','CURRENCY','INCOME_PER_YEAR','DATE','AGE'])\n",
    "mean_age = int(df['AGE'].mean())\n",
    "df['AGE'] = df['AGE'].fillna(value = mean_age) #fill with the average value for this column\n",
    "print(df.AGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows and columns can be done with the `drop()` method. The `axis` argument indicates whether rows (axis=0) or columns (axis=1) will be removed.  \n",
    "`drop()` returns a new dataframe object. If the `inplace=True` argument is used, the current dataframe is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 23: Delete columns\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 120)\n",
    "#pd.show_versions()\n",
    "\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "#Remove a column - axis = 1\n",
    "df1 = df.drop(\"ID_CLIENT\", axis=1)\n",
    "print(df1.head())\n",
    "print('-'*40)\n",
    "# Remove a column – using the columns argument\n",
    "df2 = df.drop(columns=\"AGE\")    #pandas ver. 0.21.0+ only ! check pd.show_versions()\n",
    "print(df2.head())\n",
    "print('-'*40)\n",
    "#Remove a list of columns, save as a new csv file\n",
    "df3 = df.drop([\"JOB\", \"SEX\"], axis=1)\n",
    "print(df3.head())\n",
    "df3.to_csv('clients_df.csv', index = False)\n",
    "print('-'*40)\n",
    "#Remove column – modify the current dataframe:\n",
    "# inplace = True, drop() returns None\n",
    "df.drop(\"INCOME_PER_YEAR\", axis=1, inplace = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 24: Delete rows (records)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "# Remove rows 3, 5, 8\n",
    "df4 = df.drop([3,5,8], axis=0)\n",
    "print(df4.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default row index (integer) can be replaced with values from column(s) of the dataframe, using the `set_index()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 25\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 120)\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "\n",
    "# Remove clients that are Engineers.\n",
    "# set_index() sets the JOB column as index. This enables\n",
    "# us to use JOB values to select rows.\n",
    "df5 = df.set_index(\"JOB\")\n",
    "df5.drop(\"Engineer\", axis=0, inplace = True)\n",
    "print(df5.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizing the data import from csv  \n",
    "When reading a csv file, we can choose specific columns only (`usecols` argument) and skip specific rows ( `skiprows/skipfooter` arguments).  \n",
    "The number of rows to be read is specified with `nrows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 26:\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv', \n",
    "     usecols = ['NAME_CLIENT','JOB'],\n",
    "     skiprows = [6,7,9])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 27: Restrict the number of rows read to 6 with nrows\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv', \n",
    "     nrows=6, \n",
    "     usecols = ['NAME_CLIENT','INCOME_PER_YEAR'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting rows in the dataframe  \n",
    "The `sort_values()` method returns a new, sorted dataframe object. For more details, see [this link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html?highlight=sort_values#pandas.DataFrame.sort_values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 28:Sorting examples\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path+'clients_leasing20.csv')\n",
    "df7 = df.sort_values(by='INCOME_PER_YEAR')\n",
    "print(df7.loc[ : , ['NAME_CLIENT','INCOME_PER_YEAR']].head(10))\n",
    "print('-'*40)\n",
    "\n",
    "df8=df.sort_values(by='AGE', ascending=False) # sort descending\n",
    "print(df8.loc[ : , ['NAME_CLIENT','AGE']].head(10))\n",
    "print('-'*40)\n",
    "\n",
    "df9=df.sort_values(by=['JOB', 'AGE']) #multiple sort\n",
    "print(df9.loc[ : , ['NAME_CLIENT','JOB', 'AGE']].head(10))\n",
    "print('-'*40)\n",
    "\n",
    "df10=df.sort_values(by=['JOB', 'INCOME_PER_YEAR'], ascending=[True, False]) #multiple sort with direction\n",
    "print(df10.loc[ : , ['NAME_CLIENT','JOB', 'INCOME_PER_YEAR']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rename()` method renames columns. The `columns` argument takes a dictionary with current and new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 29\n",
    "import pandas as pd\n",
    "df = pd.read_csv('clients_leasing20.csv')\n",
    "\n",
    "#df = df.rename(columns={\"ID_CLIENT\": \"Id\"})\n",
    "#df = df.rename(columns={\"JOB\": \"Position\"})\n",
    "df=df.rename(columns={\"ID_CLIENT\": \"ID\", \"JOB\": \"Position\"})\n",
    "print(df.columns)\n",
    "print('-'*40)\n",
    "\n",
    "# Applying a string function to col. names\n",
    "df=df.rename(columns=str.lower) \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Using the csv module to read .csv files\n",
    "A `csv.reader` object is created and used to access the data, based on an open text file in csv format. This object can be iterated in a for loop, to process each row of data.  \n",
    "When opening the csv file, the `newline=\"\"` argument should be used to ensure proper end-of-line handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 30: using csv.reader\n",
    "import csv\n",
    "with open(path+'clients_leasing20.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 31: reading a column of a .csv file\n",
    "#import csv\n",
    "with open(path+'clients_leasing20.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print (row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 32: Reading columns of a .csv file \n",
    "#import csv\n",
    "with open(path+'clients_leasing20.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print (row[1],row[7]) # columns NAME_CLIENT and AGE\n",
    "        #print(row[0:3])      #first 3 cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `enumerate()` built-in function is used to provide an automatic counter when iterating the rows of the reader object (see also: [`enumerate()` documentation](https://docs.python.org/3.7/library/functions.html?highlight=enumerate#enumerate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 33: using enumerate() to read the first 10 records\n",
    "#import csv\n",
    "with open(path+'clients_leasing20.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        print(row)\n",
    "        if(i >= 10):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, an `islice` object from the `itertools` module can be used. (see also: [islice documentation](https://docs.python.org/3.7/library/itertools.html#itertools.islice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 34: Reading the first 10 records with islice\n",
    "#import csv\n",
    "from itertools import islice\n",
    "\n",
    "with open(path+'clients_leasing20.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in islice(reader, 10): \n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 35: Reading csv columns into lists (vectors)\n",
    "id_client = []\n",
    "name_client = []\n",
    "sex = []\n",
    "with open(path+'clients_leasing20.csv', 'r', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        id_client.append(row[0])\n",
    "        name_client.append(row[1])\n",
    "        sex.append(row[3])\n",
    "print(id_client)\n",
    "print(name_client)\n",
    "print(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 36: Reading from a csv file with csv.reader and processing data (formatted output)\n",
    "#import sys\n",
    "#print(sys.version) #show python version\n",
    "\n",
    "import csv\n",
    "with open(path+'employees.txt', newline='') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in reader:\n",
    "        if line_count == 0:\n",
    "            #print('Column names: {}'.format(\", \".join(row))) #Python version < 3.6\n",
    "            print(f'Column names: {\", \".join(row)}') #Python 3.6+ ONLY ! check sys.version()\n",
    "            line_count += 1\n",
    "        else:\n",
    "            #print('\\t{} works in: {}, born in: {}'.format(row[0],row[1],row[2])) # Python version < 3.6\n",
    "            print(f'\\t{row[0]} works in: {row[1]}, born in: {row[2]}.') #Python 3.6+ \n",
    "            line_count += 1\n",
    "    #print('{} lines were processed.'.format(line_count)) #Python version < 3.6\n",
    "    print(f'{line_count} lines were processed.') #Python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `csv.DictReader` object can be used instead of `reader`, to read data into dictionaries. (see the [csv.DictReader documentation](https://docs.python.org/3.7/library/csv.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 37: Read data from a text file into a dictionary. \n",
    "# The first line in the file contains the field names.\n",
    "#import csv\n",
    "with open(path+'employees.txt', newline='') as f:\n",
    "    reader = csv.DictReader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 38: using DictReader, the field delimiter ';' is specified\n",
    "#import csv\n",
    "with open(path+'employees1.txt', newline='') as f:\n",
    "    reader = csv.DictReader(f, delimiter =';')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to a csv file can be done with `csv.writer` or `csv.DictWriter`, using the `writerow()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 39: using the csv.writer, writerow() method\n",
    "#import csv\n",
    "with open(path+'employees.csv', mode='w', newline='') as f: #create a new file\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Name', 'Dept', 'Month'])\n",
    "    writer.writerow(['Cosmin Antonescu', 'Marketing', 'Noiembrie'])\n",
    "    writer.writerow(['Eugenia Marin', 'Vanzari', 'Iulie'])\n",
    "\n",
    "#check the file contents:\n",
    "with open(path+'employees.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 40: using the csv.DictWriter\n",
    "#import csv\n",
    "with open(path+'employees1.csv', mode='w', newline='') as f:\n",
    "    fieldnames = ['Name', 'Dept', 'Month']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'Name': 'Constantinescu Andrei', 'Dept': 'Accounting', 'Month': 'April'})\n",
    "    writer.writerow({'Name': 'Iliescu Emil', 'Dept': 'IT', 'Month': 'May'})\n",
    "\n",
    "#check the file contents:\n",
    "with open(path+'employees1.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Reading data from .json files with the json module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 41: Use the json module, json.load() method\n",
    "import json\n",
    "from pprint import pprint     #\"pretty print\" data structures\n",
    "\n",
    "with open('clienti_daune100.json') as f:\n",
    "    data = json.load(f)    #load data into a list of dictionaries\n",
    "pprint(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 42: Processing  json data. \n",
    "# Count the word frequency in the field \"Dauna\" (car problem description):\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#open file clienti_daune.json and load data\n",
    "with open ('clienti_daune100.json') as f:\n",
    "    data=json.load(f)\n",
    "\n",
    "#get a list of all the words in the field \"Dauna\"\n",
    "word_list=[]\n",
    "for rec in data:   \n",
    "      word_list=word_list + rec['Dauna'].lower().split()\n",
    "print(word_list[:100], '...', len(word_list), 'words in total.' )\n",
    "\n",
    "# store word counts in a dictionary\n",
    "dict = {}\n",
    "for word in word_list:\n",
    "    if word not in dict:\n",
    "        dict[word] = 1\n",
    "    else:\n",
    "        dict[word] += 1\n",
    "        \n",
    "# Create a list of words and their frequencies, sort it descending and print it\n",
    "w_freq = []\n",
    "for key, value in dict.items():\n",
    "    w_freq.append((value, key))   #append tuple to list\n",
    "w_freq.sort(reverse=True)\n",
    "pprint(w_freq[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Pandas Documentation, https://pandas.pydata.org/docs/getting_started/index.html   \n",
    "J. VanderPlas, Python Data Science Handbook - https://jakevdp.github.io/PythonDataScienceHandbook/  \n",
    "https://realpython.com/python-csv/  \n",
    "https://www.shanelynn.ie/python-pandas-read_csv-load-data-from-csv-files/  \n",
    "https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Exercises\n",
    "\n",
    "1) Create a new pandas dataframe based on the clients_leasing500.csv file, with the columns: name_client, deposit_amount and prescoring, if val_credits_ron is 0 and deposit_amount > 1000; change the value for prescoring to 6 if deposit_amount > 5000; save to a new csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) In example 42, modify the code to display the words with a frequency (count) higher than or equal to 30, ignoring the words 'the', 'and', 'to', 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
